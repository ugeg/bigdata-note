#CAP理论
Consistence 一致性：多个副本之间数据一致(强一致性)
Availability 可用性：系统对外提供的服务一直可用
Partitioning 分区容错性 :允许节点之间的网络故障
三个条件不能同时满足。
---
#BASE理论(可用性和一致性的均衡)
Basically Available 基本可用：如响应时间损失，功能损失
Soft state 软状态：允许系统的数据有中间状态，不同节点数据存在延时
Eventually consistent 最终一致性：在延迟期限后数据一致(因果一致，读己之所写，单调读，单调写)
---
#2PC(Two-Phase Commit)
1. 准备阶段（投票阶段）
协调者给参与者发送prepare消息。参与者执行事务写redo undo志，但不提交,成功后向协调者报告
2. 提交阶段〈执行阶段）
协调者收到所有参与者成功的消息，发送commit消息,否则发生rollback消息.参与者执行命令,释放事务资源,返回消息
* 缺点:
    1. 同步阻塞．所有参与节点都要阻塞
    2. 单点故障：协调者故障导致参与者一直阻塞
    3. 数据不一致：部分参与者收到commit消息后协调者故障,其余参与者无法commit
    4.过于保守：任意节点失败导致完全失败
---
#3PC
在2PC基础上引入超时机制。将准备阶段再分为2个阶段
1. CanCommit阶段
协调者向参与者发送CanCommit请求,参与者反馈Yes
2. PreCommit阶段
协调者收到全部yes响应，发送PreCommit请求,否则发送abort请求.参与者执行事务写redo undo日志,但不提交,成功后向协调者报告
3. doCommit阶段
协调者收到所有参与者成功的消息，发送doCommit消息,否则发送abort消息.参与者执行命令,释放事务资源,返回消息
在doCommit阶段，如果参与者未及时收到或abort消息,在超时之后继续执行提交.
* 3PC解决了2PC的单点故障,且减小阻塞(第一阶段不阻塞).但如果参与者为收到abort消息而超时提交后,会导致数据不一致
---
#Paxos算法
* Basic Paxos
	1. 预提案阶段：
		1. Prepare:Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。
		2. Promise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。
			两个承诺：
			1. 不再接受Proposal ID小于等于（注意：这里是<= ）当前请求的Prepare请求。
			2. 不再接受Proposal ID小于（注意：这里是< ）当前请求的Propose请求。
			一个应答：
			不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值
	2. 提案阶段：
		1. Propose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。
		2. Accept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。
		3. Learn: Proposer收到多数Acceptors的Accept后，决议形成，将形成的决议发送给所有Learners。
	* 每个提议者不会执着于让自己的提案通过，而是执着于让提案尽快达成一致意见。在收到Acceptor已记录其他更小proposal_id的提案时,令自己的提案等于那个提案值.
	* 理论上Paxos存在永远无法达成一致的可能，一个提案a提出时可能有一个更大proposal_id的预提案b提出,b的提案提出又可能有c的预提案提出,导致无限递归
* Multi-Paxos
首先需要选举Leader，可执行一次Basic Paxos实例来选举出一个Leader。选出Leader之后只能由Leader提交Proposal，这样可以跳过预提案阶段
---
#Raft算法
1. 领导选举
	1. 跟随者Follwer如果一段时间没有收到任何消息(选举超时),则发起选举(RequestVoteRPCs).选举超时时间是随机的,使的超时时间短的跟随者先发起选举并赢得选举.
	2. 跟随者增加自己当前任期号(term)转换为候选者Candidate.如果已有leader,leader收到选举消息自动变为follwer.
	3. 候选者必须联系到大多数节点,因此至少包括一个已存在最新已提交日志的节点,投票者会拒绝日志没有自己新的投票请求.(如果两份日志最后的条目的任期号不同,那么任期号大的日志更加新.如果两份日志最后的条目任期号相同,那么日志比较长的那个就更加新.)Raft永远不会通过计算副本书目的方式去提交一个之前任期内的日志条目,只有领导人当前任期里的日志条目通过计算副本数目可以被提交,之前的日志条目也会被间接地提交.因此可以保证选举成功的新领导者Leader拥有最新的已提交日志,
	4. 如果选举不成功,重新选举.
2. 日志复制:
	1. 领导者收到客户端请求,将指令追加到日志(包括状态机指令和任期号),并发起AppendEntriesRPCs给其他节点,当被大多数节点复制后,领导者应用这条日志到自己的状态机(Commit)并返回给客户端,并通知其他跟随者应用这条日志到自己的状态机(Commit)并返回给客户端,并通知其他跟随者应用到状态机(Commit),不断重试直到所有跟随者都成功.如果领导者与跟随者日志不一致,强制使用领导者日志覆盖跟随者.
---
#ZAB协议(zookeeper)
1. 恢复模式(选举):
	1. 每个节点一轮选举可以多次投票(只要遇到更大的票)并通知所有节点.这样 不存在选举不成功的情况,但选举时间比raft更久.
	2. 超时策略:
		1. raft中follower检测到leader心跳超时会发起新投票,原leader遇到新投票变成follower
		2.zookeeper中leader和follower都会检测超时,follower超时进入looking状态,如果leader与其他follower连接良好,不会触发选举
	3. 日志策略
		1. zookeeper的日志不是连续的,leader为每个follower维护一个队列用于存放差异数据,follower在加入集群是需要阻塞leader的写入,差异放入队列后释放锁,然后应用到新follower
	4. 上轮leader残留数据处理策略:
		1. raft:过半或未过半的日志都判定未提交,只有当前term提交才顺便提交之前term的日志
		2. zookeeper:判定为提交,选举完成后进行leader和follower同步
2. 广播模式:
	1. 与raft的日志复制类似
---
#Consistent Hash一致性哈希算法(redis)
设计一个hash环,机器分布在环上,数据hash后(顺时针)找到最近的节点进行存储.这样增减机器只会影响一个节点.为避免负载不均匀,在空闲的地方设计虚拟节点映射到真实节点上.